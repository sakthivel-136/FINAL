# -*- coding: utf-8 -*-
"""mic_chat

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ei3nfgH_cdVVbbmd-_EQurgt7s4rvQs
"""



import streamlit as st
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer

# Page setup
st.set_page_config(page_title="ğŸ“ Kamaraj College FAQ Chatbot", layout="centered")

# Load and cache model/data
@st.cache_resource
def load_model_and_data():
    df = pd.read_csv("kamaraj_college_faq.csv")
    df.dropna(inplace=True)

    le = LabelEncoder()
    df["Answer_Label"] = le.fit_transform(df["Answer"])

    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(df["Question"])
    y = df["Answer_Label"]

    model = LogisticRegression()
    model.fit(X, y)

    return model, vectorizer, le

# Load model and tools
model, vectorizer, label_encoder = load_model_and_data()

# Title and intro
st.title("ğŸ“ Kamaraj College FAQ Chatbot")
st.markdown("Ask me anything related to **Kamaraj College of Engineering and Technology**! ğŸ¤–")

# Voice input integration with Gradio
st.markdown("ğŸ¤ [Click here to speak your question using mic](https://82e74598108b8cf7cd.gradio.live)", unsafe_allow_html=True)

# Text input box
user_question = st.text_input("ğŸ’¬ Type your question here:")

# Predict and respond
if st.button("ğŸ” Get Answer"):
    if not user_question.strip():
        st.warning("âš ï¸ Please enter a valid question.")
    else:
        vector = vectorizer.transform([user_question])
        prediction = model.predict(vector)[0]
        answer = label_encoder.inverse_transform([prediction])[0]
        st.success(f"ğŸŸ¢ **Answer:** {answer}")

