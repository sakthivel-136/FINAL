# -*- coding: utf-8 -*-
"""mic_chat

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ei3nfgH_cdVVbbmd-_EQurgt7s4rvQs
"""

import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
import queue
import threading
import numpy as np
import pandas as pd
import os
import tempfile
import speech_recognition as sr
from scipy.io.wavfile import write
from gtts import gTTS
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Constants
CSV_FILE = "kcet.csv"
VECTOR_FILE = "vectorized.pkl"
THRESHOLD = 0.75
WAKE_WORD = "hey kcet"

# Load or vectorize
@st.cache_resource
def load_or_vectorize():
    if os.path.exists(VECTOR_FILE):
        with open(VECTOR_FILE, "rb") as f:
            vectorizer, vectors, df = pickle.load(f)
    else:
        df = pd.read_csv(CSV_FILE)
        df['Question'] = df['Question'].str.strip().str.lower()
        vectorizer = TfidfVectorizer()
        vectors = vectorizer.fit_transform(df['Question'])
        with open(VECTOR_FILE, "wb") as f:
            pickle.dump((vectorizer, vectors, df), f)
    return vectorizer, vectors, df

vectorizer, vectors, df = load_or_vectorize()
audio_queue = queue.Queue()

# Audio handler
class AudioProcessor(AudioProcessorBase):
    def recv_queued(self, frames):
        for frame in frames:
            audio = frame.to_ndarray()
            audio_queue.put(audio)
        return frames[-1]

# Streamlit UI
st.set_page_config(page_title="KCET Voice Assistant", layout="centered")
st.title("üéôÔ∏è KCET Voice Assistant (with Wake Word & Live Display)")

webrtc_streamer(
    key="listen",
    mode=WebRtcMode.SENDONLY,
    audio_receiver_size=2048,
    media_stream_constraints={"audio": True, "video": False},
    audio_processor_factory=AudioProcessor,
)

transcript_placeholder = st.empty()
bot_response = st.empty()
status = st.empty()

# Background worker
def listen_and_process():
    recognizer = sr.Recognizer()

    while True:
        if audio_queue.qsize() > 300:
            status.info("üé§ Listening...")
            audio_data = np.concatenate(list(audio_queue.queue), axis=0).astype(np.int16)
            audio_queue.queue.clear()

            temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
            write(temp_wav.name, 16000, audio_data)

            with sr.AudioFile(temp_wav.name) as source:
                try:
                    audio = recognizer.record(source)
                    query = recognizer.recognize_google(audio).lower()
                except:
                    status.warning("‚ùå Could not understand audio.")
                    continue

            if WAKE_WORD in query:
                status.success("‚úÖ Wake word detected! Waiting for your question...")

                # Listen again for actual question
                time.sleep(1)
                while audio_queue.qsize() < 300:
                    time.sleep(0.5)

                audio_data = np.concatenate(list(audio_queue.queue), axis=0).astype(np.int16)
                audio_queue.queue.clear()
                temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                write(temp_wav.name, 16000, audio_data)

                with sr.AudioFile(temp_wav.name) as source:
                    try:
                        audio = recognizer.record(source)
                        query = recognizer.recognize_google(audio).lower()
                        words = query.split()
                        live = ""
                        for word in words:
                            live += word + " "
                            transcript_placeholder.markdown(f"üßë You: `{live.strip()}`")
                            time.sleep(0.4)
                    except:
                        transcript_placeholder.warning("Couldn't catch that.")
                        continue

                # Process Query
                query_vector = vectorizer.transform([query])
                similarity = cosine_similarity(query_vector, vectors)
                max_sim = similarity.max()
                max_index = similarity.argmax()

                if max_sim >= THRESHOLD:
                    answer = df.iloc[max_index]['Answer']
                else:
                    answer = "I'm not sure how to answer that. Please try again."

                bot_response.markdown(f"ü§ñ **Bot:** {answer}")

                # TTS
                tts = gTTS(answer)
                tts_fp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                tts.save(tts_fp.name)
                st.audio(tts_fp.name, format="audio/mp3")
                status.empty()

# Start listener once
if "started" not in st.session_state:
    threading.Thread(target=listen_and_process, daemon=True).start()
    st.session_state["started"] = True

