# -*- coding: utf-8 -*-
"""mic_chat

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ei3nfgH_cdVVbbmd-_EQurgt7s4rvQs
"""

import streamlit as st
import pandas as pd
import os
import pickle
from gtts import gTTS
import tempfile
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import speech_recognition as sr
from pydub import AudioSegment

# Constants
VECTOR_FILE = "vectorized.pkl"
CSV_FILE = "kcet.csv"
THRESHOLD = 0.8

# Text-to-speech
def speak(text):
    tts = gTTS(text)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        tts.save(fp.name)
        st.audio(fp.name, format='audio/mp3')

# Load or vectorize
def load_or_vectorize():
    if os.path.exists(VECTOR_FILE):
        with open(VECTOR_FILE, "rb") as f:
            vectorizer, vectors, df = pickle.load(f)
    else:
        df = pd.read_csv(CSV_FILE)
        df['Question'] = df['Question'].str.strip().str.lower()
        vectorizer = TfidfVectorizer()
        vectors = vectorizer.fit_transform(df['Question'])
        with open(VECTOR_FILE, "wb") as f:
            pickle.dump((vectorizer, vectors, df), f)
    return vectorizer, vectors, df

vectorizer, vectors, df = load_or_vectorize()

# Speech recognition from file
def transcribe_audio(uploaded_file):
    recognizer = sr.Recognizer()
    audio_file_path = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name

    # Convert mp3 to wav if needed
    if uploaded_file.name.endswith(".mp3"):
        audio = AudioSegment.from_mp3(uploaded_file)
        audio.export(audio_file_path, format="wav")
    else:
        with open(audio_file_path, "wb") as f:
            f.write(uploaded_file.read())

    with sr.AudioFile(audio_file_path) as source:
        audio = recognizer.record(source)
        try:
            return recognizer.recognize_google(audio)
        except sr.UnknownValueError:
            return ""
        except sr.RequestError:
            return ""

# Streamlit UI
st.set_page_config(page_title="KCET Voice ChatBot", layout="centered")
st.title("ğŸ“ KCET Voice Assistant")

option = st.radio("Choose Input Method:", ["ğŸ™ï¸ Upload Audio", "âŒ¨ï¸ Type Question"])

if option == "ğŸ™ï¸ Upload Audio":
    uploaded = st.file_uploader("Upload your question as MP3 or WAV", type=["wav", "mp3"])
    if uploaded and st.button("Ask"):
        query = transcribe_audio(uploaded)
        if query:
            st.markdown(f"**ğŸ‘¤ You said:** {query}")
        else:
            st.warning("Couldn't understand the audio.")
elif option == "âŒ¨ï¸ Type Question":
    query = st.text_input("Enter your question:")
    if query and st.button("Ask"):
        st.markdown(f"**ğŸ‘¤ You asked:** {query}")

if 'query' in locals() and query:
    query_vector = vectorizer.transform([query.lower()])
    similarity = cosine_similarity(query_vector, vectors)
    max_sim = similarity.max()
    max_index = similarity.argmax()

    if max_sim >= THRESHOLD:
        answer = df.iloc[max_index]['Answer']
    else:
        answer = "âŒ Sorry, I couldn't understand that. Please rephrase."

    st.markdown(f"**ğŸ¤– Bot:** {answer}")
    speak(answer)


        st.markdown(f"**ğŸ¤– Bot:** {answer}")
        speak(answer)
    else:
        st.warning("â— Could not capture any clear speech. Please try again.")
