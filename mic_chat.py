# -*- coding: utf-8 -*-
"""mic_chat

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ei3nfgH_cdVVbbmd-_EQurgt7s4rvQs
"""


import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode
import av
import queue
import threading
import time
import tempfile
from gtts import gTTS
from scipy.io.wavfile import write
import numpy as np
import pandas as pd
import os
import pickle
import speech_recognition as sr
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Constants
CSV_FILE = "kcet.csv"
VECTOR_FILE = "vectorized.pkl"
THRESHOLD = 0.8
WAKE_WORD = "hey kcet" # Ensure this matches exactly what you say

# Load or vectorize CSV data
def load_or_vectorize():
    if os.path.exists(VECTOR_FILE):
        with open(VECTOR_FILE, "rb") as f:
            vectorizer, vectors, df = pickle.load(f)
    else:
        df = pd.read_csv(CSV_FILE)
        df['Question'] = df['Question'].str.strip().str.lower()
        vectorizer = TfidfVectorizer()
        vectors = vectorizer.fit_transform(df['Question'])
        with open(VECTOR_FILE, "wb") as f:
            pickle.dump((vectorizer, vectors, df), f)
    return vectorizer, vectors, df

vectorizer, vectors, df = load_or_vectorize()

# --- Initialize session state variables at the very top ---
if "audio_queue" not in st.session_state:
    st.session_state["audio_queue"] = queue.Queue()
if "listening_active_event" not in st.session_state:
    st.session_state["listening_active_event"] = threading.Event()
if "listening_thread" not in st.session_state:
    st.session_state["listening_thread"] = None
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []
# Add a debug message session state for granular feedback to the user
if "debug_message" not in st.session_state:
    st.session_state["debug_message"] = "Initializing..."
if "show_history" not in st.session_state: # New session state for history visibility
    st.session_state["show_history"] = False

st.set_page_config(page_title="üéôÔ∏è KCET Voice Assistant", layout="centered")
st.markdown("""
    <style>
    .bot-bubble {
        background-color: #e0f7fa;
        color: #006064;
        padding: 1em;
        border-radius: 12px;
        margin-bottom: 10px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    .user-bubble {
        background-color: #fce4ec;
        color: #880e4f;
        padding: 1em;
        border-radius: 12px;
        margin-bottom: 10px;
        text-align: right;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    .typing {
        font-style: italic;
        color: #9e9e9e;
        animation: pulse 1s infinite;
    }
    @keyframes pulse {
        0% { opacity: 0.3; }
        50% { opacity: 1; }
        100% { opacity: 0.3; }
    }
    </style>
""", unsafe_allow_html=True)

st.title("üéôÔ∏è KCET Voice Assistant")
status = st.empty()
transcript_placeholder = st.empty()
bot_response = st.empty()
# manual_input_placeholder = st.empty() # Moved below for better flow
debug_placeholder = st.empty() # Placeholder for debug messages

class AudioProcessor:
    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
        if st.session_state["listening_active_event"].is_set():
            audio = frame.to_ndarray()
            try:
                st.session_state["audio_queue"].put_nowait(audio)
            except queue.Full:
                print("Audio queue is full!")
        return frame

def listen_and_process_thread(audio_q: queue.Queue, listening_event: threading.Event):
    recognizer = sr.Recognizer()

    while listening_event.is_set():
        try:
            if audio_q.qsize() > 200:
                st.session_state["debug_message"] = "Processing audio chunk..."
                audio_data_list = []
                while not audio_q.empty():
                    try:
                        audio_data_list.append(audio_q.get_nowait())
                    except queue.Empty:
                        break

                if not audio_data_list:
                    time.sleep(0.01)
                    continue

                audio_data = np.concatenate(audio_data_list, axis=0).astype(np.int16)
                st.session_state["debug_message"] = f"Audio chunk collected. Size: {len(audio_data)} samples."

                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_wav:
                    write(temp_wav.name, 16000, audio_data)
                    temp_wav_path = temp_wav.name

                with sr.AudioFile(temp_wav_path) as source:
                    try:
                        st.session_state["debug_message"] = "Attempting speech recognition..."
                        audio = recognizer.record(source)
                        query = recognizer.recognize_google(audio, language="en-IN").lower()
                        print(f"Recognized (in thread): '{query}'")
                        st.session_state["debug_message"] = f"Recognized: '{query}'"

                        if WAKE_WORD in query:
                            print(f"Wake word '{WAKE_WORD}' detected!")
                            st.session_state["debug_message"] = "Wake word detected! Processing command..."
                            processed_query = query.replace(WAKE_WORD, "").strip()
                            if processed_query:
                                print(f"Processing command: '{processed_query}'")
                                query_vector = vectorizer.transform([processed_query])
                                similarity = cosine_similarity(query_vector, vectors)
                                max_sim = similarity.max()
                                max_index = similarity.argmax()

                                if max_sim >= THRESHOLD:
                                    answer = df.iloc[max_index]['Answer']
                                    print(f"Answer found (Similarity: {max_sim:.2f}): {answer}")
                                else:
                                    answer = "ü§ñ I couldn't understand that. Please ask again."
                                    print(f"No answer found (Similarity: {max_sim:.2f}). Defaulting.")

                                st.session_state["new_query"] = processed_query
                                st.session_state["new_answer"] = answer
                                st.session_state["debug_message"] = "Response generated."
                            else:
                                print("Wake word detected, but no command followed.")
                                st.session_state["debug_message"] = "Wake word heard, awaiting command."

                            while not audio_q.empty():
                                try:
                                    audio_q.get_nowait()
                                except queue.Empty:
                                    pass
                        else:
                            st.session_state["debug_message"] = f"'{query}' (no wake word)"

                    except sr.UnknownValueError:
                        print("Speech Recognition could not understand audio (in thread)")
                        st.session_state["debug_message"] = "Could not understand audio."
                    except sr.RequestError as e:
                        print(f"Could not request results from Google Speech Recognition service (in thread); {e}")
                        st.session_state["debug_message"] = f"SR service error: {e}"
                    except Exception as e:
                        print(f"An unexpected error occurred during audio processing in thread: {e}")
                        st.session_state["debug_message"] = f"An unexpected error occurred during audio processing in thread: {e}"
                    finally:
                        if os.path.exists(temp_wav_path):
                            os.unlink(temp_wav_path)

            else:
                if audio_q.qsize() < 10:
                    st.session_state["debug_message"] = f"Waiting for more audio... (Queue size: {audio_q.qsize()})"
                time.sleep(0.05)

        except Exception as e:
            print(f"FATAL ERROR in listen_and_process_thread: {e}")
            st.session_state["debug_message"] = f"FATAL THREAD ERROR: {e}"
            listening_event.clear()
            break

# --- Streamlit UI and Thread Management ---

webrtc_ctx = webrtc_streamer(
    key="voice",
    mode=WebRtcMode.SENDONLY,
    audio_processor_factory=AudioProcessor,
    media_stream_constraints={"audio": True, "video": False},
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
)

# Start/Stop the listener thread based on WebRTC status
if webrtc_ctx.state.playing and not st.session_state["listening_active_event"].is_set():
    st.session_state["listening_active_event"].set()
    if st.session_state["listening_thread"] is None or not st.session_state["listening_thread"].is_alive():
        print("Starting new listening thread...")
        st.session_state["listening_thread"] = threading.Thread(
            target=listen_and_process_thread,
            args=(st.session_state["audio_queue"], st.session_state["listening_active_event"]),
            daemon=True
        )
        st.session_state["listening_thread"].start()
    status.write("üëÇ Listening for 'Hey KCET'...")
    st.session_state["debug_message"] = "WebRTC connected. Listener thread active."
elif not webrtc_ctx.state.playing and st.session_state["listening_active_event"].is_set():
    print("Stopping listening thread...")
    st.session_state["listening_active_event"].clear()
    if st.session_state["listening_thread"] and st.session_state["listening_thread"].is_alive():
        st.session_state["listening_thread"].join(timeout=2)
    st.session_state["listening_thread"] = None

    while not st.session_state["audio_queue"].empty():
        try:
            st.session_state["audio_queue"].get_nowait()
        except queue.Empty:
            pass
    status.write("üî¥ Not listening. Click 'Start' to activate.")
    st.session_state["debug_message"] = "WebRTC disconnected. Listener thread stopped."
elif not webrtc_ctx.state.playing and not st.session_state["listening_active_event"].is_set():
    status.write("üî¥ Not listening. Click 'Start' to activate.")
    st.session_state["debug_message"] = "Awaiting WebRTC connection."

# Display debug messages
debug_placeholder.info(st.session_state["debug_message"])

# Manual input box
with st.form("manual_input_form"): # Removed manual_input_placeholder since it's a form now
    user_query = st.text_input("üí¨ Type your question if you prefer not to speak:", "")
    submitted = st.form_submit_button("Submit")
    if submitted and user_query.strip():
        query_vector = vectorizer.transform([user_query.strip().lower()])
        similarity = cosine_similarity(query_vector, vectors)
        max_sim = similarity.max()
        max_index = similarity.argmax()

        if max_sim >= THRESHOLD:
            answer = df.iloc[max_index]['Answer']
        else:
            answer = "ü§ñ I couldn't understand that. Please ask again."

        st.session_state["new_query"] = user_query.strip().lower()
        st.session_state["new_answer"] = answer
        st.session_state["debug_message"] = "Manual query processed."

# Display chat history and responses
if "new_query" in st.session_state and "new_answer" in st.session_state:
    user = st.session_state.pop("new_query")
    answer = st.session_state.pop("new_answer")

    st.session_state["chat_history"].append((user, answer))

    transcript_placeholder.markdown(f"<div class='user-bubble'>üë§ {user}</div>", unsafe_allow_html=True)
    bot_response.markdown(f"<div class='bot-bubble typing'>ü§ñ Thinking...</div>", unsafe_allow_html=True)
    time.sleep(1) # Simulate thinking time
    bot_response.markdown(f"<div class='bot-bubble'>ü§ñ {answer}</div>", unsafe_allow_html=True)

    try:
        tts = gTTS(answer)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tts_fp:
            tts.save(tts_fp.name)
            tts_file_path = tts_fp.name
        st.audio(tts_file_path, format="audio/mp3")
        os.unlink(tts_file_path)
    except Exception as e:
        st.error(f"Error generating or playing audio: {e}")
    st.session_state["debug_message"] = "Response displayed and audio played."

---

## üìú Chat History

# Add the "Show History" button
if st.button("Show History"):
    st.session_state["show_history"] = not st.session_state["show_history"] # Toggle visibility

# Only display history if the flag is True
if st.session_state["show_history"]:
    if not st.session_state["chat_history"]:
        st.info("No chat history yet.")
    else:
        for user_hist, bot_hist in reversed(st.session_state["chat_history"]):
            st.markdown(f"<div class='user-bubble'>üë§ {user_hist}</div>", unsafe_allow_html=True)
            st.markdown(f"<div class='bot-bubble'>ü§ñ {bot_hist}</div>", unsafe_allow_html=True)
            st.markdown("<br>", unsafe_allow_html=True)


