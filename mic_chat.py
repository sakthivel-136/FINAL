# -*- coding: utf-8 -*-
"""mic_chat

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ei3nfgH_cdVVbbmd-_EQurgt7s4rvQs
"""
import streamlit as st
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode
import numpy as np
import queue
import tempfile
import os
import pandas as pd
import pickle
from gtts import gTTS
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import speech_recognition as sr
from scipy.io.wavfile import write
import threading
import time

# Load or vectorize CSV
VECTOR_FILE = "vectorized.pkl"
CSV_FILE = "kcet.csv"
THRESHOLD = 0.75

@st.cache_resource
def load_or_vectorize():
    if os.path.exists(VECTOR_FILE):
        with open(VECTOR_FILE, "rb") as f:
            vectorizer, vectors, df = pickle.load(f)
    else:
        df = pd.read_csv(CSV_FILE)
        df['Question'] = df['Question'].str.strip().str.lower()
        vectorizer = TfidfVectorizer()
        vectors = vectorizer.fit_transform(df['Question'])
        with open(VECTOR_FILE, "wb") as f:
            pickle.dump((vectorizer, vectors, df), f)
    return vectorizer, vectors, df

vectorizer, vectors, df = load_or_vectorize()
audio_queue = queue.Queue()

class AudioProcessor(AudioProcessorBase):
    def recv_queued(self, frames):
        for frame in frames:
            audio = frame.to_ndarray()
            audio_queue.put(audio)
        return frames[-1]

# Streamlit UI
st.set_page_config(page_title="KCET Voice Assistant", layout="centered")
st.title("üéôÔ∏è KCET Voice Assistant (Auto Mode)")
st.markdown("Speak your question. The bot will respond automatically.")

webrtc_streamer(
    key="voice",
    mode=WebRtcMode.SENDONLY,
    audio_receiver_size=2048,
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    media_stream_constraints={"audio": True, "video": False},
    audio_processor_factory=AudioProcessor,
)

# Auto-processing loop
def process_audio_stream():
    last_len = 0
    while True:
        time.sleep(3)  # check every few seconds
        current_len = audio_queue.qsize()
        if current_len > 0 and current_len == last_len:
            with st.spinner("‚è≥ Processing your voice..."):
                audio_data = np.concatenate(list(audio_queue.queue), axis=0).astype(np.int16)
                audio_queue.queue.clear()

                temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
                write(temp_wav.name, 16000, audio_data)

                recognizer = sr.Recognizer()
                with sr.AudioFile(temp_wav.name) as source:
                    try:
                        audio = recognizer.record(source)
                        query = recognizer.recognize_google(audio)
                        st.success(f"üßë You said: {query}")
                    except Exception as e:
                        st.warning("‚ùó Could not recognize speech. Try again.")
                        return

                if query:
                    query_vector = vectorizer.transform([query.lower()])
                    similarity = cosine_similarity(query_vector, vectors)
                    max_sim = similarity.max()
                    max_index = similarity.argmax()

                    if max_sim >= THRESHOLD:
                        answer = df.iloc[max_index]['Answer']
                    else:
                        answer = "‚ùå Sorry, I couldn't understand that."

                    st.markdown(f"**ü§ñ Bot:** {answer}")
                    tts = gTTS(answer)
                    audio_fp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                    tts.save(audio_fp.name)
                    st.audio(audio_fp.name, format="audio/mp3")
        last_len = current_len

# Launch audio processing in background thread
if "started" not in st.session_state:
    threading.Thread(target=process_audio_stream, daemon=True).start()
    st.session_state["started"] = True
