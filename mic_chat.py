# -*- coding: utf-8 -*-
"""mic_chat

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ei3nfgH_cdVVbbmd-_EQurgt7s4rvQs
"""
import streamlit as st
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode
import numpy as np
import queue
import tempfile
import os
import pandas as pd
import pickle
from gtts import gTTS
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import speech_recognition as sr
from scipy.io.wavfile import write

# Constants
VECTOR_FILE = "vectorized.pkl"
CSV_FILE = "kcet.csv"
THRESHOLD = 0.75

# Load or vectorize CSV
def load_or_vectorize():
    if os.path.exists(VECTOR_FILE):
        with open(VECTOR_FILE, "rb") as f:
            vectorizer, vectors, df = pickle.load(f)
    else:
        df = pd.read_csv(CSV_FILE)
        df['Question'] = df['Question'].str.strip().str.lower()
        vectorizer = TfidfVectorizer()
        vectors = vectorizer.fit_transform(df['Question'])
        with open(VECTOR_FILE, "wb") as f:
            pickle.dump((vectorizer, vectors, df), f)
    return vectorizer, vectors, df

vectorizer, vectors, df = load_or_vectorize()

# Audio queue for mic input
audio_queue = queue.Queue()

class AudioProcessor(AudioProcessorBase):
    def recv(self, frame):
        audio = frame.to_ndarray()
        audio_queue.put(audio)
        return frame

# Streamlit UI
st.set_page_config(page_title="KCET Voice Bot", layout="centered")
st.title("üéôÔ∏è KCET Voice Assistant ")

webrtc_streamer(
    key="voice",
    mode=WebRtcMode.SENDONLY,
    audio_receiver_size=1024,
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    media_stream_constraints={"audio": True, "video": False},
    audio_processor_factory=AudioProcessor,
)

# Trigger speech processing
if st.button("üß† Process My Voice"):
    recognizer = sr.Recognizer()

    if not audio_queue.empty():
        audio_data = np.concatenate(list(audio_queue.queue), axis=0).astype(np.int16)
        temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        write(temp_wav.name, 16000, audio_data)

        with sr.AudioFile(temp_wav.name) as source:
            try:
                audio = recognizer.record(source)
                query = recognizer.recognize_google(audio)
                st.success(f"üßë You said: {query}")
            except:
                query = ""
                st.warning("‚ùó Could not understand audio. Try again.")

        if query:
            query_vector = vectorizer.transform([query.lower()])
            similarity = cosine_similarity(query_vector, vectors)
            max_sim = similarity.max()
            max_index = similarity.argmax()

            if max_sim >= THRESHOLD:
                answer = df.iloc[max_index]['Answer']
            else:
                answer = "‚ùå Sorry, I couldn't understand that."

            st.markdown(f"**ü§ñ Bot:** {answer}")

            # Text to speech
            tts = gTTS(answer)
            audio_fp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
            tts.save(audio_fp.name)
            st.audio(audio_fp.name, format="audio/mp3")
    else:
        st.warning("üé§ No audio captured yet. Please speak into your mic.")
