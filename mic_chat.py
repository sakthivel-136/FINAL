# -*- coding: utf-8 -*-
"""mic_chat

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ei3nfgH_cdVVbbmd-_EQurgt7s4rvQs
"""

import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, ClientSettings
import av
import queue
import threading
import time
import tempfile
from gtts import gTTS
from scipy.io.wavfile import write
import numpy as np
import pandas as pd
import os
import pickle
import speech_recognition as sr
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Constants
CSV_FILE = "kcet.csv"
VECTOR_FILE = "vectorized.pkl"
THRESHOLD = 0.8
WAKE_WORD = "hey kcet"

# Load or vectorize CSV data
def load_or_vectorize():
    if os.path.exists(VECTOR_FILE):
        with open(VECTOR_FILE, "rb") as f:
            vectorizer, vectors, df = pickle.load(f)
    else:
        df = pd.read_csv(CSV_FILE)
        df['Question'] = df['Question'].str.strip().str.lower()
        vectorizer = TfidfVectorizer()
        vectors = vectorizer.fit_transform(df['Question'])
        with open(VECTOR_FILE, "wb") as f:
            pickle.dump((vectorizer, vectors, df), f)
    return vectorizer, vectors, df

vectorizer, vectors, df = load_or_vectorize()

audio_queue = queue.Queue()

st.set_page_config(page_title="🎙️ KCET Voice Assistant", layout="centered")
st.title("🎙️ KCET Voice Assistant (with Wake Word & Live Display)")
status = st.empty()
transcript_placeholder = st.empty()
bot_response = st.empty()

class AudioProcessor:
    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
        audio = frame.to_ndarray()
        audio_queue.put_nowait(audio)
        return frame

def listen_and_process():
    recognizer = sr.Recognizer()
    status.info("🚀 Background listener started...")

    while True:
        if audio_queue.qsize() > 100:
            status.info("🎤 Listening for Wake Word...")
            audio_data = np.concatenate(list(audio_queue.queue), axis=0).astype(np.int16)
            audio_queue.queue.clear()

            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_wav:
                write(temp_wav.name, 16000, audio_data)
                with sr.AudioFile(temp_wav.name) as source:
                    try:
                        audio = recognizer.record(source)
                        query = recognizer.recognize_google(audio).lower()
                        print(f"🎧 Transcribed: {query}")
                    except Exception as e:
                        status.error(f"Speech error: {e}")
                        continue

            if WAKE_WORD in query:
                status.success("✅ Wake word detected!")
                transcript_placeholder.markdown("🧠 Waiting for your question...")
                time.sleep(1)
                while audio_queue.qsize() < 150:
                    time.sleep(0.2)

                audio_data = np.concatenate(list(audio_queue.queue), axis=0).astype(np.int16)
                audio_queue.queue.clear()
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_wav:
                    write(temp_wav.name, 16000, audio_data)
                    with sr.AudioFile(temp_wav.name) as source:
                        try:
                            audio = recognizer.record(source)
                            query = recognizer.recognize_google(audio).lower()
                            live = ""
                            for word in query.split():
                                live += word + " "
                                transcript_placeholder.markdown(f"👤 You: `{live.strip()}`")
                                time.sleep(0.3)
                        except Exception as e:
                            status.error("❌ Failed to process your speech.")
                            continue

                query_vector = vectorizer.transform([query])
                similarity = cosine_similarity(query_vector, vectors)
                max_sim = similarity.max()
                max_index = similarity.argmax()

                if max_sim >= THRESHOLD:
                    answer = df.iloc[max_index]['Answer']
                else:
                    answer = "🤖 I couldn't understand that. Please ask again."

                bot_response.markdown(f"**🤖 Bot:** {answer}")

                tts = gTTS(answer)
                tts_fp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
                tts.save(tts_fp.name)
                st.audio(tts_fp.name, format="audio/mp3")
                status.empty()

webrtc_streamer(
    key="voice",
    mode=WebRtcMode.SENDONLY,
    audio_processor_factory=AudioProcessor,
    client_settings=ClientSettings(media_stream_constraints={"audio": True, "video": False}),
)

threading.Thread(target=listen_and_process, daemon=True).start()

