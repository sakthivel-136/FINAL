# -*- coding: utf-8 -*-
"""mic_chat

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ei3nfgH_cdVVbbmd-_EQurgt7s4rvQs
"""

# mic_chat.py

import streamlit as st
import pandas as pd
import os
import pickle
from gtts import gTTS
import tempfile
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import speech_recognition as sr
from pydub import AudioSegment

# Constants
CSV_FILE = "kcet.csv"
VECTOR_FILE = "vectorized.pkl"
THRESHOLD = 0.8

# Text-to-speech response
def speak(text):
    tts = gTTS(text)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
        tts.save(fp.name)
        st.audio(fp.name, format="audio/mp3")

# Load vectorized data or create from scratch
def load_or_vectorize():
    if os.path.exists(VECTOR_FILE):
        with open(VECTOR_FILE, "rb") as f:
            vectorizer, vectors, df = pickle.load(f)
    else:
        df = pd.read_csv(CSV_FILE)
        df['Question'] = df['Question'].str.strip().str.lower()
        vectorizer = TfidfVectorizer()
        vectors = vectorizer.fit_transform(df['Question'])
        with open(VECTOR_FILE, "wb") as f:
            pickle.dump((vectorizer, vectors, df), f)
    return vectorizer, vectors, df

# Transcribe uploaded audio file (wav/mp3)
def transcribe_audio(uploaded_file):
    recognizer = sr.Recognizer()
    audio_path = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name

    # Convert mp3 to wav
    if uploaded_file.name.endswith(".mp3"):
        sound = AudioSegment.from_mp3(uploaded_file)
        sound.export(audio_path, format="wav")
    else:
        with open(audio_path, "wb") as f:
            f.write(uploaded_file.read())

    with sr.AudioFile(audio_path) as source:
        audio = recognizer.record(source)
        try:
            return recognizer.recognize_google(audio)
        except sr.UnknownValueError:
            return ""
        except sr.RequestError:
            return ""

# Setup UI
st.set_page_config(page_title="KCET Voice ChatBot", layout="centered")
st.title("ğŸ“ KCET Voice Assistant")

vectorizer, vectors, df = load_or_vectorize()

# Input Method
input_method = st.radio("Choose your input method:", ["ğŸ¤ Upload Audio", "âŒ¨ï¸ Type Question"])

query = ""

if input_method == "ğŸ¤ Upload Audio":
    uploaded = st.file_uploader("Upload your voice question (MP3 or WAV)", type=["mp3", "wav"])
    if uploaded and st.button("Ask from Audio"):
        query = transcribe_audio(uploaded)
        if query:
            st.success(f"ğŸ—£ï¸ You said: **{query}**")
        else:
            st.warning("â— Couldn't understand the audio.")

elif input_method == "âŒ¨ï¸ Type Question":
    query = st.text_input("Type your question here:")
    if st.button("Ask from Text") and not query:
        st.warning("Please enter a question.")

# Process the question if available
if query:
    query_vector = vectorizer.transform([query.lower()])
    similarity = cosine_similarity(query_vector, vectors)
    max_sim = similarity.max()
    max_index = similarity.argmax()

    if max_sim >= THRESHOLD:
        answer = df.iloc[max_index]['Answer']
    else:
        answer = "âŒ Sorry, I couldn't understand that. Please rephrase."

    st.markdown(f"**ğŸ¤– Bot:** {answer}")
    speak(answer)
