# -*- coding: utf-8 -*-
"""mic_chat

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ei3nfgH_cdVVbbmd-_EQurgt7s4rvQs
"""

import streamlit as st
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase
import numpy as np
import queue
import os
import tempfile
import pandas as pd
import pickle
from gtts import gTTS
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import speech_recognition as sr
from pydub import AudioSegment

# Constants
VECTOR_FILE = "vectorized.pkl"
CSV_FILE = "kcet.csv"
THRESHOLD = 0.8

# Load or vectorize data
def load_or_vectorize():
    if os.path.exists(VECTOR_FILE):
        with open(VECTOR_FILE, "rb") as f:
            vectorizer, vectors, df = pickle.load(f)
    else:
        df = pd.read_csv(CSV_FILE)
        df['Question'] = df['Question'].str.strip().str.lower()
        vectorizer = TfidfVectorizer()
        vectors = vectorizer.fit_transform(df['Question'])
        with open(VECTOR_FILE, "wb") as f:
            pickle.dump((vectorizer, vectors, df), f)
    return vectorizer, vectors, df

vectorizer, vectors, df = load_or_vectorize()

# Audio processing using webrtc
audio_queue = queue.Queue()

class AudioProcessor(AudioProcessorBase):
    def recv(self, frame):
        audio = frame.to_ndarray()
        audio_queue.put(audio)
        return frame

# Streamlit UI
st.set_page_config(page_title="KCET Voice Bot", layout="centered")
st.title("üé§ KCET Voice Assistant (No PyAudio)")

webrtc_streamer(
    key="speech",
    mode="sendonly",
    audio_receiver_size=1024,
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    media_stream_constraints={"audio": True, "video": False},
    audio_processor_factory=AudioProcessor,
)

# Record and transcribe
if st.button("üé§ Process Latest Audio"):
    recognizer = sr.Recognizer()

    if not audio_queue.empty():
        audio_data = np.concatenate(list(audio_queue.queue), axis=0).astype(np.int16)
        temp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        from scipy.io.wavfile import write
        write(temp_file.name, 16000, audio_data)

        with sr.AudioFile(temp_file.name) as source:
            audio = recognizer.record(source)
            try:
                query = recognizer.recognize_google(audio)
                st.success(f"üßë You said: {query}")
            except:
                st.warning("Could not understand speech")
                query = ""
    else:
        st.warning("No audio captured.")
        query = ""

    if query:
        query_vector = vectorizer.transform([query.lower()])
        similarity = cosine_similarity(query_vector, vectors)
        max_sim = similarity.max()
        max_index = similarity.argmax()

        if max_sim >= THRESHOLD:
            answer = df.iloc[max_index]['Answer']
        else:
            answer = "‚ùå Sorry, I couldn't understand. Please try again."

        st.markdown(f"**ü§ñ Bot:** {answer}")
        
        tts = gTTS(answer)
        tts_fp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tts.save(tts_fp.name)
        st.audio(tts_fp.name, format="audio/mp3")
